{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/vmonjezi/.local/lib/python3.8/site-packages/llvmlite/llvmpy/__init__.py:3: UserWarning: The module `llvmlite.llvmpy` is deprecated and will be removed in the future.\n",
      "  warnings.warn(\n",
      "/home/users/vmonjezi/.local/lib/python3.8/site-packages/llvmlite/llvmpy/core.py:8: UserWarning: The module `llvmlite.llvmpy.core` is deprecated and will be removed in the future. Equivalent functionality is provided by `llvmlite.ir`.\n",
      "  warnings.warn(\n",
      "/home/users/vmonjezi/.local/lib/python3.8/site-packages/llvmlite/llvmpy/passes.py:17: UserWarning: The module `llvmlite.llvmpy.passes` is deprecated and will be removed in the future. If you are using this code, it should be inlined into your own project.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census 9\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/util/dispatch.py:1096: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0113 14:50:55.483668 140072096503616 deprecation.py:545] From /usr/lib/python3/dist-packages/tensorflow/python/util/dispatch.py:1096: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:50:55.537920 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n",
      "`np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "`np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "Trying to unpickle estimator KMeans from version 0.22.2.post1 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718 0 118 Percentage discriminatory inputs of local search- 16.411682892906814\n",
      "1523 1 150 Percentage discriminatory inputs of local search- 9.84251968503937\n",
      "2335 2 255 Percentage discriminatory inputs of local search- 10.91609589041096\n",
      "Total Inputs are 2335\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 255\n",
      "Time to first 0.4011\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:51:18.433231 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754 0 26 Percentage discriminatory inputs of local search- 3.443708609271523\n",
      "1540 1 267 Percentage discriminatory inputs of local search- 17.326411421155093\n",
      "2240 2 393 Percentage discriminatory inputs of local search- 17.53681392235609\n",
      "Total Inputs are 2240\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 393\n",
      "Time to first 0.0131\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:51:39.523353 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778 0 14 Percentage discriminatory inputs of local search- 1.797175866495507\n",
      "1609 1 73 Percentage discriminatory inputs of local search- 4.53416149068323\n",
      "2418 2 270 Percentage discriminatory inputs of local search- 11.161637040099215\n",
      "Total Inputs are 2418\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 270\n",
      "Time to first 0.0132\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:52:00.480959 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738 0 136 Percentage discriminatory inputs of local search- 18.403247631935045\n",
      "1552 1 375 Percentage discriminatory inputs of local search- 24.146812620734064\n",
      "2367 2 526 Percentage discriminatory inputs of local search- 22.21283783783784\n",
      "Total Inputs are 2367\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 526\n",
      "Time to first 0.0132\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:52:21.498244 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605 0 163 Percentage discriminatory inputs of local search- 26.897689768976896\n",
      "1372 1 411 Percentage discriminatory inputs of local search- 29.934450109249816\n",
      "2163 2 486 Percentage discriminatory inputs of local search- 22.45841035120148\n",
      "Total Inputs are 2163\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 486\n",
      "Time to first 0.013\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:52:43.040973 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760 0 25 Percentage discriminatory inputs of local search- 3.28515111695138\n",
      "1594 1 157 Percentage discriminatory inputs of local search- 9.843260188087774\n",
      "2452 2 411 Percentage discriminatory inputs of local search- 16.754993885038726\n",
      "Total Inputs are 2452\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 411\n",
      "Time to first 0.0135\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:53:04.318486 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824 0 277 Percentage discriminatory inputs of local search- 33.57575757575758\n",
      "1619 1 529 Percentage discriminatory inputs of local search- 32.65432098765432\n",
      "2362 2 800 Percentage discriminatory inputs of local search- 33.85526872619551\n",
      "Total Inputs are 2362\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 800\n",
      "Time to first 0.0167\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:53:25.702634 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 0 191 Percentage discriminatory inputs of local search- 24.708926261319533\n",
      "1580 1 400 Percentage discriminatory inputs of local search- 25.30044275774826\n",
      "2360 2 720 Percentage discriminatory inputs of local search- 30.495552731893266\n",
      "Total Inputs are 2360\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 720\n",
      "Time to first 0.0127\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:53:46.346385 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 0 153 Percentage discriminatory inputs of local search- 19.79301423027167\n",
      "1589 1 283 Percentage discriminatory inputs of local search- 17.79874213836478\n",
      "2396 2 597 Percentage discriminatory inputs of local search- 24.90613266583229\n",
      "Total Inputs are 2396\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 597\n",
      "Time to first 0.0127\n",
      "Time to 1000 ID 0\n",
      "census 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:54:07.687310 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810 0 444 Percentage discriminatory inputs of local search- 54.747225647348955\n",
      "1603 1 584 Percentage discriminatory inputs of local search- 36.408977556109726\n",
      "2381 2 751 Percentage discriminatory inputs of local search- 31.52812762384551\n",
      "Total Inputs are 2381\n",
      "Total discriminatory inputs of global search- 3\n",
      "Total discriminatory inputs of local search- 751\n",
      "Time to first 0.0129\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:54:29.009963 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794 0 178 Percentage discriminatory inputs of local search- 22.38993710691824\n",
      "1528 1 203 Percentage discriminatory inputs of local search- 13.27665140614781\n",
      "Total Inputs are 1528\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 203\n",
      "Time to first 0.0132\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:54:58.852606 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834 0 247 Percentage discriminatory inputs of local search- 29.58083832335329\n",
      "1600 1 430 Percentage discriminatory inputs of local search- 26.858213616489696\n",
      "Total Inputs are 1600\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 430\n",
      "Time to first 0.0127\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:55:27.182162 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771 0 150 Percentage discriminatory inputs of local search- 19.4300518134715\n",
      "1570 1 578 Percentage discriminatory inputs of local search- 36.79185232336092\n",
      "Total Inputs are 1570\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 578\n",
      "Time to first 0.0129\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:55:55.925287 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794 0 469 Percentage discriminatory inputs of local search- 58.9937106918239\n",
      "1575 1 882 Percentage discriminatory inputs of local search- 55.964467005076145\n",
      "Total Inputs are 1575\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 882\n",
      "Time to first 0.0127\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:56:21.063394 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749 0 373 Percentage discriminatory inputs of local search- 49.733333333333334\n",
      "1543 1 895 Percentage discriminatory inputs of local search- 57.96632124352331\n",
      "Total Inputs are 1543\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 895\n",
      "Time to first 0.0128\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:56:45.705295 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778 0 335 Percentage discriminatory inputs of local search- 43.003851091142494\n",
      "1546 1 718 Percentage discriminatory inputs of local search- 46.41241111829347\n",
      "Total Inputs are 1546\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 718\n",
      "Time to first 0.013\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:57:12.228721 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824 0 382 Percentage discriminatory inputs of local search- 46.303030303030305\n",
      "1604 1 763 Percentage discriminatory inputs of local search- 47.53894080996885\n",
      "Total Inputs are 1604\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 763\n",
      "Time to first 0.0129\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:57:38.016549 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786 0 453 Percentage discriminatory inputs of local search- 57.560355781448536\n",
      "1562 1 763 Percentage discriminatory inputs of local search- 48.816378758797185\n",
      "Total Inputs are 1562\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 763\n",
      "Time to first 0.0128\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:58:04.321013 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799 0 464 Percentage discriminatory inputs of local search- 57.99999999999999\n",
      "1502 1 837 Percentage discriminatory inputs of local search- 55.688622754491014\n",
      "Total Inputs are 1502\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 837\n",
      "Time to first 0.0129\n",
      "Time to 1000 ID 0\n",
      "census 8\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:58:27.696760 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803 0 54 Percentage discriminatory inputs of local search- 6.7164179104477615\n",
      "1609 1 510 Percentage discriminatory inputs of local search- 31.67701863354037\n",
      "Total Inputs are 1609\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 510\n",
      "Time to first 0.0138\n",
      "Time to 1000 ID 0\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:58:57.758291 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783 0 687 Percentage discriminatory inputs of local search- 87.62755102040816\n",
      "Total Inputs are 783\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 687\n",
      "Time to first 0.0138\n",
      "Time to 1000 ID 0\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:59:21.182828 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795 0 288 Percentage discriminatory inputs of local search- 36.18090452261307\n",
      "Total Inputs are 795\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 288\n",
      "Time to first 0.0129\n",
      "Time to 1000 ID 0\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 14:59:46.013616 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697 0 373 Percentage discriminatory inputs of local search- 53.43839541547278\n",
      "1532 1 652 Percentage discriminatory inputs of local search- 42.53098499673842\n",
      "Total Inputs are 1532\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 652\n",
      "Time to first 0.013\n",
      "Time to 1000 ID 0\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:00:26.339210 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809 0 720 Percentage discriminatory inputs of local search- 88.88888888888889\n",
      "1596 1 1111 Percentage discriminatory inputs of local search- 69.56793988728866\n",
      "Total Inputs are 1596\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 1111\n",
      "Time to first 0.0134\n",
      "Time to 1000 ID 36.3884\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:01:05.237008 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755 0 555 Percentage discriminatory inputs of local search- 73.4126984126984\n",
      "Total Inputs are 755\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 555\n",
      "Time to first 0.013\n",
      "Time to 1000 ID 0\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:01:25.681720 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777 0 616 Percentage discriminatory inputs of local search- 79.17737789203085\n",
      "Total Inputs are 777\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 616\n",
      "Time to first 0.0128\n",
      "Time to 1000 ID 0\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:01:46.220744 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754 0 506 Percentage discriminatory inputs of local search- 67.01986754966887\n",
      "1559 1 1072 Percentage discriminatory inputs of local search- 68.71794871794872\n",
      "Total Inputs are 1559\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 1072\n",
      "Time to first 0.0143\n",
      "Time to 1000 ID 32.6339\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:02:23.236886 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803 0 275 Percentage discriminatory inputs of local search- 34.20398009950249\n",
      "Total Inputs are 803\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 275\n",
      "Time to first 0.0128\n",
      "Time to 1000 ID 0\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:02:48.222474 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666 0 53 Percentage discriminatory inputs of local search- 7.946026986506746\n",
      "Total Inputs are 666\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 53\n",
      "Time to first 0.0131\n",
      "Time to 1000 ID 0\n",
      "census 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:03:14.380674 140072096503616 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806 0 378 Percentage discriminatory inputs of local search- 46.84014869888476\n",
      "Total Inputs are 806\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 378\n",
      "Time to first 0.0128\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:03:41.652406 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719 0 412 Percentage discriminatory inputs of local search- 57.22222222222222\n",
      "Total Inputs are 719\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 412\n",
      "Time to first 0.0187\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:04:11.192749 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714 0 473 Percentage discriminatory inputs of local search- 66.15384615384615\n",
      "Total Inputs are 714\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 473\n",
      "Time to first 0.0137\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:04:41.265454 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704 0 539 Percentage discriminatory inputs of local search- 76.45390070921985\n",
      "Total Inputs are 704\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 539\n",
      "Time to first 0.0134\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:05:07.346950 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697 0 619 Percentage discriminatory inputs of local search- 88.68194842406876\n",
      "Total Inputs are 697\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 619\n",
      "Time to first 0.0136\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:05:31.111455 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745 0 586 Percentage discriminatory inputs of local search- 78.55227882037534\n",
      "Total Inputs are 745\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 586\n",
      "Time to first 0.0138\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:06:03.828645 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737 0 362 Percentage discriminatory inputs of local search- 49.05149051490515\n",
      "Total Inputs are 737\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 362\n",
      "Time to first 0.0133\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:06:33.791650 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737 0 430 Percentage discriminatory inputs of local search- 58.265582655826556\n",
      "Total Inputs are 737\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 430\n",
      "Time to first 0.0135\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:07:03.834680 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743 0 526 Percentage discriminatory inputs of local search- 70.6989247311828\n",
      "Total Inputs are 743\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 526\n",
      "Time to first 0.0144\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:07:31.067243 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696 0 202 Percentage discriminatory inputs of local search- 28.98134863701578\n",
      "Total Inputs are 696\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 202\n",
      "Time to first 0.0136\n",
      "Time to 1000 ID 0\n",
      "credit 13\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:08:06.909065 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744 0 505 Percentage discriminatory inputs of local search- 67.78523489932886\n",
      "Total Inputs are 744\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 505\n",
      "Time to first 0.0137\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:08:36.059452 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737 0 251 Percentage discriminatory inputs of local search- 34.010840108401084\n",
      "1463 1 395 Percentage discriminatory inputs of local search- 26.98087431693989\n",
      "Total Inputs are 1463\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 395\n",
      "Time to first 0.8178\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:08:58.571163 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726 0 155 Percentage discriminatory inputs of local search- 21.320495185694636\n",
      "1446 1 221 Percentage discriminatory inputs of local search- 15.272978576364892\n",
      "Total Inputs are 1446\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 221\n",
      "Time to first 0.017\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:09:19.409121 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726 0 200 Percentage discriminatory inputs of local search- 27.51031636863824\n",
      "1446 1 360 Percentage discriminatory inputs of local search- 24.8790601243953\n",
      "Total Inputs are 1446\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 360\n",
      "Time to first 0.0134\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:09:40.541752 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 0 144 Percentage discriminatory inputs of local search- 20.57142857142857\n",
      "1434 1 182 Percentage discriminatory inputs of local search- 12.682926829268293\n",
      "Total Inputs are 1434\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 182\n",
      "Time to first 0.0128\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:10:02.256757 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731 0 26 Percentage discriminatory inputs of local search- 3.551912568306011\n",
      "1436 1 30 Percentage discriminatory inputs of local search- 2.0876826722338206\n",
      "Total Inputs are 1436\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 30\n",
      "Time to first 0.0128\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:10:23.421568 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728 0 106 Percentage discriminatory inputs of local search- 14.540466392318244\n",
      "1464 1 222 Percentage discriminatory inputs of local search- 15.15358361774744\n",
      "Total Inputs are 1464\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 222\n",
      "Time to first 0.0174\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:10:44.018246 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719 0 211 Percentage discriminatory inputs of local search- 29.305555555555557\n",
      "1469 1 244 Percentage discriminatory inputs of local search- 16.598639455782312\n",
      "Total Inputs are 1469\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 244\n",
      "Time to first 0.0129\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:11:04.516780 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744 0 133 Percentage discriminatory inputs of local search- 17.85234899328859\n",
      "1490 1 272 Percentage discriminatory inputs of local search- 18.24279007377599\n",
      "Total Inputs are 1490\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 272\n",
      "Time to first 0.0126\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:11:25.696730 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751 0 220 Percentage discriminatory inputs of local search- 29.25531914893617\n",
      "1506 1 328 Percentage discriminatory inputs of local search- 21.76509621765096\n",
      "Total Inputs are 1506\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 328\n",
      "Time to first 0.0126\n",
      "Time to 1000 ID 0\n",
      "credit 9\n",
      "INFO:tensorflow:Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:11:46.851882 140072096503616 saver.py:1399] Restoring parameters from ../models/credit/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731 0 80 Percentage discriminatory inputs of local search- 10.92896174863388\n",
      "1458 1 226 Percentage discriminatory inputs of local search- 15.49006168608636\n",
      "Total Inputs are 1458\n",
      "Total discriminatory inputs of global search- 2\n",
      "Total discriminatory inputs of local search- 226\n",
      "Time to first 0.0133\n",
      "Time to 1000 ID 0\n",
      "bank 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/bank/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:12:07.466544 140072096503616 saver.py:1399] Restoring parameters from ../models/bank/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595 0 413 Percentage discriminatory inputs of local search- 69.29530201342283\n",
      "Total Inputs are 595\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 413\n",
      "Time to first 0.2153\n",
      "Time to 1000 ID 0\n",
      "bank 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/bank/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:12:27.954560 140072096503616 saver.py:1399] Restoring parameters from ../models/bank/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 0 555 Percentage discriminatory inputs of local search- 58.359621451104104\n",
      "Total Inputs are 950\n",
      "Total discriminatory inputs of global search- 1\n",
      "Total discriminatory inputs of local search- 555\n",
      "Time to first 0.013\n",
      "Time to 1000 ID 0\n",
      "bank 1\n",
      "INFO:tensorflow:Restoring parameters from ../models/bank/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0113 15:13:10.157118 140072096503616 saver.py:1399] Restoring parameters from ../models/bank/test.model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-422c1d33a8fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_iter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maximum iteration of global perturbation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ReLU_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ReLU5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"the name of bias layer of dnn model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-422c1d33a8fe>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m     dnn_fair_testing(dataset=FLAGS.dataset,\n\u001b[0m\u001b[1;32m    411\u001b[0m                      \u001b[0msensitive_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msens_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                      \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-422c1d33a8fe>\u001b[0m in \u001b[0;36mdnn_fair_testing\u001b[0;34m(dataset, sensitive_param, model_path, cluster_num, max_global, max_local, max_iter, ReLU_name)\u001b[0m\n\u001b[1;32m    330\u001b[0m                                 \u001b[0mminimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"method\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                                 \u001b[0mlocal_perturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocal_Perturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                                 basinhopping(evaluate_local, sample, stepsize=1.0, take_step=local_perturbation,\n\u001b[0m\u001b[1;32m    333\u001b[0m                                              \u001b[0mminimizer_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                                              niter=max_local)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36mbasinhopping\u001b[0;34m(func, x0, niter, T, stepsize, minimizer_kwargs, take_step, accept_test, callback, interval, disp, niter_success, seed)\u001b[0m\n\u001b[1;32m    674\u001b[0m                \" successfully\"]\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mnew_global_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36mone_cycle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mnew_global_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0maccept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_monte_carlo_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36m_monte_carlo_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# do a local minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mminres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_after_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mx_after_quench\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0menergy_after_quench\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_basinhopping.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x0)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    607\u001b[0m                                   **options)\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    610\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-422c1d33a8fe>\u001b[0m in \u001b[0;36mevaluate_local\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    258\u001b[0m                         \u001b[0;32mglobal\u001b[0m \u001b[0mtime_to_1st\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                         \u001b[0;32mglobal\u001b[0m \u001b[0mtime_to_1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_for_error_condition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensitive_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msensitive_param\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensitive_param\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-422c1d33a8fe>\u001b[0m in \u001b[0;36mcheck_for_error_condition\u001b[0;34m(conf, sess, x, preds, t, sens)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mtnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msens\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mlabel_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtnew\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabel_new\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Fairness-testing/ADF-Test/adf_baseline/NF_main/src/../utils/utils_tf.py\u001b[0m in \u001b[0;36mmodel_argmax\u001b[0;34m(sess, x, predictions, samples, feed)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    971\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m     fetch_handler = _FetchHandler(\n\u001b[0m\u001b[1;32m   1179\u001b[0m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \"\"\"\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5764\u001b[0m       with super(_DefaultGraphStack,\n\u001b[1;32m   5765\u001b[0m                  self).get_controller(default) as g, context.graph_mode():\n\u001b[0;32m-> 5766\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5767\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5768\u001b[0m       \u001b[0;31m# If an exception is raised here it may be hiding a related exception in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "import copy,time , csv\n",
    "from tensorflow.python.platform import flags\n",
    "from scipy.optimize import basinhopping\n",
    "from nf_data.census import census_data\n",
    "from nf_data.credit import credit_data\n",
    "from nf_data.compas import compas_data\n",
    "from nf_data.default import default_data\n",
    "from nf_data.bank import bank_data\n",
    "from nf_data.heart import heart_data\n",
    "from nf_data.diabetes import diabetes_data\n",
    "from nf_data.students import students_data\n",
    "from nf_data.meps15 import meps15_data\n",
    "from nf_data.meps16 import meps16_data\n",
    "from nf_model.dnn_models import dnn\n",
    "from utils.utils_tf import model_prediction, model_argmax, model_loss\n",
    "from utils.config import census, credit, bank, compas, default, heart, diabetes, students , meps15, meps16\n",
    "from src.nf_utils import cluster, gradient_graph_neuron\n",
    "\n",
    "olderr = np.seterr(all='ignore')\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "FLAGS = flags.FLAGS\n",
    "perturbation_size = 1\n",
    "\n",
    "def check_for_error_condition(conf, sess, x, preds, t, sens):\n",
    "    \"\"\"\n",
    "    Check whether the test case is an individual discriminatory instance\n",
    "    :param conf: the configuration of dataset\n",
    "    :param sess: TF session\n",
    "    :param x: input placeholder\n",
    "    :param preds: the model's symbolic output\n",
    "    :param t: test case\n",
    "    :param sens: the index of sensitive feature\n",
    "    :return: whether it is an individual discriminatory instance\n",
    "    \"\"\"\n",
    "    t = t.astype('int')\n",
    "    label = model_argmax(sess, x, preds, np.array([t]))\n",
    "    # check for all the possible values of sensitive feature\n",
    "    for val in range(conf.input_bounds[sens-1][0], conf.input_bounds[sens-1][1]+1):\n",
    "        if val != t[sens-1]:\n",
    "            tnew = copy.deepcopy(t)\n",
    "            tnew[sens-1] = val\n",
    "            label_new = model_argmax(sess, x, preds, np.array([tnew]))\n",
    "            if label_new != label:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def seed_test_input(clusters, limit):\n",
    "    \"\"\"\n",
    "    Select the seed inputs for fairness testing\n",
    "    :param clusters: the results of K-means clustering\n",
    "    :param limit: the size of seed inputs wanted\n",
    "    :return: a sequence of seed inputs\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    rows = []\n",
    "    max_size = max([len(c[0]) for c in clusters])\n",
    "    while i < max_size:\n",
    "        if len(rows) == limit:\n",
    "            break\n",
    "        for c in clusters:\n",
    "            if i >= len(c[0]):\n",
    "                continue\n",
    "            row = c[0][i]\n",
    "            rows.append(row)\n",
    "            if len(rows) == limit:\n",
    "                break\n",
    "        i += 1\n",
    "    return np.array(rows)\n",
    "\n",
    "def clip(input, conf):\n",
    "    \"\"\"\n",
    "    Clip the generating instance with each feature to make sure it is valid\n",
    "    :param input: generating instance\n",
    "    :param conf: the configuration of dataset\n",
    "    :return: a valid generating instance\n",
    "    \"\"\"\n",
    "    for i in range(len(input)):\n",
    "        input[i] = max(input[i], conf.input_bounds[i][0])\n",
    "        input[i] = min(input[i], conf.input_bounds[i][1])\n",
    "    return input\n",
    "\n",
    "class Local_Perturbation(object):\n",
    "    \"\"\"\n",
    "    The  implementation of local perturbation\n",
    "    \"\"\"\n",
    "    def __init__(self, sess,  x, nx, x_grad, nx_grad, n_value, sens_param, input_shape, conf):\n",
    "        \"\"\"\n",
    "        Initial function of local perturbation\n",
    "        :param sess: TF session\n",
    "        :param x: input placeholder for x\n",
    "        :param nx: input placeholder for nx (sensitive attributes of nx and x are different)\n",
    "        :param x_grad: the gradient graph for x\n",
    "        :param nx_grad: the gradient graph for nx\n",
    "        :param n_value: the discriminatory value of sensitive feature\n",
    "        :param sens_param: the index of sensitive feature\n",
    "        :param input_shape: the shape of dataset\n",
    "        :param conf: the configuration of dataset\n",
    "        \"\"\"\n",
    "        self.sess = sess\n",
    "        self.grad = x_grad\n",
    "        self.ngrad = nx_grad\n",
    "        self.x = x\n",
    "        self.nx = nx\n",
    "        self.n_value = n_value\n",
    "        self.input_shape = input_shape\n",
    "        self.sens_param = sens_param\n",
    "        self.conf = conf\n",
    "\n",
    "    def softmax(self, m):\n",
    "        probs = np.exp(m - np.max(m))\n",
    "        probs /= np.sum(probs)\n",
    "        return probs\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Local perturbation\n",
    "        :param x: input instance for local perturbation\n",
    "        :return: new potential individual discriminatory instance\n",
    "        \"\"\"\n",
    "        # perturbation\n",
    "        s = np.random.choice([1.0, -1.0]) * perturbation_size\n",
    "        n_x = x.copy()\n",
    "        n_x[self.sens_param - 1] = self.n_value\n",
    "        # compute the gradients of an individual discriminatory instance pairs\n",
    "        ind_grad,n_ind_grad = self.sess.run([self.grad,self.ngrad], feed_dict={self.x:np.array([x]), self.nx: np.array([n_x])})\n",
    "\n",
    "        if np.zeros(self.input_shape).tolist() == ind_grad[0].tolist() and np.zeros(self.input_shape).tolist() == \\\n",
    "                n_ind_grad[0].tolist():\n",
    "            probs = 1.0 / (self.input_shape-1) * np.ones(self.input_shape)\n",
    "            probs[self.sens_param - 1] = 0\n",
    "        else:\n",
    "            # nomalize the reciprocal of gradients (prefer the low impactful feature)\n",
    "            grad_sum = 1.0 / (abs(ind_grad[0]) + abs(n_ind_grad[0]))\n",
    "            grad_sum[self.sens_param - 1] = 0\n",
    "            probs = grad_sum / np.sum(grad_sum)\n",
    "        probs = probs / probs.sum()\n",
    "        # probs = self.softmax(probs)\n",
    "\n",
    "        # randomly choose the feature for local perturbation\n",
    "        try:\n",
    "            index = np.random.choice(range(self.input_shape) , p=probs)\n",
    "        except:\n",
    "            index = 0\n",
    "        local_cal_grad = np.zeros(self.input_shape)\n",
    "        local_cal_grad[index] = 1.0\n",
    "        x = clip(x + s * local_cal_grad, self.conf).astype(\"int\")\n",
    "        return x\n",
    "\n",
    "def dnn_fair_testing(dataset, sensitive_param, model_path, cluster_num, max_global, max_local, max_iter, ReLU_name):\n",
    "    \"\"\"\n",
    "    The implementation of NF\n",
    "    :param dataset: the name of testing dataset\n",
    "    :param sensitive_param: the index of sensitive feature\n",
    "    :param model_path: the path of testing model\n",
    "    :param cluster_num: the number of clusters to form as well as the number of\n",
    "            centroids to generate\n",
    "    :param max_global: the maximum number of samples for global search\n",
    "    :param max_local: the maximum number of samples for local search\n",
    "    :param max_iter: the maximum iteration of global perturbation\n",
    "    :param ReLU_name: the name of bias layer of dnn model\n",
    "    \"\"\"\n",
    "    data = {\"census\":census_data, \"credit\":credit_data, \"bank\":bank_data, \"compas\":compas_data, \n",
    "            \"default\": default_data, \"heart\":heart_data, \"diabetes\":diabetes_data, \n",
    "            \"students\":students_data, \"meps15\":meps15_data, \"meps16\":meps16_data}\n",
    "    data_config = {\"census\":census, \"credit\":credit, \"bank\":bank, \"compas\":compas, \"default\":default,\n",
    "                  \"heart\":heart , \"diabetes\":diabetes,\"students\":students, \"meps15\":meps15, \"meps16\":meps16}\n",
    "\n",
    "    # prepare the testing data and model\n",
    "    \n",
    "\n",
    "    def get_weights(X, sensitive_param, sess, x, nx, x_hidden, nx_hidden, alpha = 0.5):\n",
    "        nX = copy.copy(X)\n",
    "        senss = data_config[dataset].input_bounds[sensitive_param - 1]\n",
    "        eq = np.array(nX[:, sensitive_param - 1] == senss[0]).astype(np.int)\n",
    "        neq = -eq + 1\n",
    "        nX[:, sensitive_param - 1] = eq * senss[-1] + neq * senss[0]        \n",
    "        sa, nsa = sess.run([x_hidden, nx_hidden], feed_dict={x: X, nx: nX})\n",
    "        sf = np.mean(np.abs(sa) + np.abs(nsa), axis=0)\n",
    "        # print(sf)\n",
    "        num = 0 if int(alpha * len(sf)) - 1 < 0 else int(alpha * len(sf)) - 1\n",
    "        ti = np.argsort(sf)[len(sf) - num - 1]\n",
    "        alpha = sf[ti]\n",
    "        weights = np.array(sf >= alpha).astype(np.int)\n",
    "        return weights\n",
    "\n",
    "    tf.set_random_seed(1234)\n",
    "    config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "    config.allow_soft_placement= True\n",
    "#     config = tf.ConfigProto()\n",
    "#     config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    \n",
    "    for dataset in data.keys():\n",
    "    \n",
    "        if dataset == 'credit': sens_p = [13,9]\n",
    "        elif dataset == 'census': sens_p = [9,8,1]\n",
    "        elif dataset == 'bank': sens_p = [1]\n",
    "        elif dataset == 'compas': sens_p = [3,2,1]\n",
    "        elif dataset == 'default': sens_p = [5,2]\n",
    "        elif dataset == 'heart': sens_p = [2,1]\n",
    "        elif dataset == 'diabetes': sens_p = [8]\n",
    "        elif dataset == 'students': sens_p = [3,2]\n",
    "        elif dataset == 'meps15': sens_p = [10,2,1]\n",
    "        elif dataset == 'meps16': sens_p = [10,2,1]\n",
    "        \n",
    "        X, Y, input_shape, nb_classes = data[dataset]()\n",
    "        for sen in sens_p:\n",
    "            sensitive_param = sen\n",
    "           \n",
    "            for trial in range(10):\n",
    "                print(dataset,sensitive_param )\n",
    "                sd = 0\n",
    "                RQ2_table =[]\n",
    "                with tf.Graph().as_default():\n",
    "                    sess = tf.Session(config=config)\n",
    "                    x = tf.placeholder(tf.float32, shape=input_shape)\n",
    "                    nx = tf.placeholder(tf.float32, shape=input_shape)\n",
    "                    model = dnn(input_shape, nb_classes)\n",
    "                    preds = model(x)\n",
    "                    x_hidden = model.get_layer(x, ReLU_name)\n",
    "                    nx_hidden = model.get_layer(nx, ReLU_name)\n",
    "                    saver = tf.train.Saver()\n",
    "                    model_path = '../models/'\n",
    "                    model_path = model_path + dataset + \"/test.model\"\n",
    "                    saver.restore(sess, model_path)\n",
    "                    weights = get_weights(X,sensitive_param, sess,x,nx,x_hidden,nx_hidden)\n",
    "                    x_grad,nx_grad = gradient_graph_neuron(x, nx, x_hidden, nx_hidden, weights)\n",
    "\n",
    "                    clf = cluster(dataset, cluster_num)\n",
    "                    clusters = [np.where(clf.labels_==i) for i in range(cluster_num)]\n",
    "                    # store the result of fairness testing\n",
    "                    tot_inputs = set()\n",
    "                    global_disc_inputs = set()\n",
    "                    global_disc_inputs_list = []\n",
    "                    local_disc_inputs = set()\n",
    "                    local_disc_inputs_list = []\n",
    "                    value_list = []\n",
    "                    suc_idx = []\n",
    "                    #-----\n",
    "                    global time_to_1st\n",
    "                    global time_to_1000\n",
    "                    tot_global_inputs = set()\n",
    "                    tot_local_inputs = set()\n",
    "                    time_to_1st = 0\n",
    "                    time_to_1000 = 0\n",
    "                    #--------\n",
    "                    def evaluate_local(inp):\n",
    "                        \"\"\"\n",
    "                        Evaluate whether the test input after local perturbation is an individual discriminatory instance\n",
    "                        :param inp: test input\n",
    "                        :return: whether it is an individual discriminatory instance\n",
    "                        \"\"\"\n",
    "                        global time_to_1st\n",
    "                        global time_to_1000\n",
    "                        result = check_for_error_condition(data_config[dataset], sess, x, preds, inp, sensitive_param)\n",
    "                        temp = copy.deepcopy(inp.astype('int').tolist())\n",
    "                        temp = temp[:sensitive_param - 1] + temp[sensitive_param:]\n",
    "                        tot_inputs.add(tuple(temp))\n",
    "                         #-------------\n",
    "                        if (tuple(temp) not in tot_local_inputs) and (tuple(temp) not in tot_global_inputs):\n",
    "                            tot_local_inputs.add(tuple(temp))\n",
    "                        #---------------\n",
    "                        if result and (tuple(temp) not in global_disc_inputs) and (tuple(temp) not in local_disc_inputs):\n",
    "                            if time_to_1st == 0:\n",
    "                                time_to_1st = round(time.time() - time1,4)\n",
    "                            local_disc_inputs.add(tuple(temp))\n",
    "                            local_disc_inputs_list.append(temp)\n",
    "                        if len(global_disc_inputs) + len(local_disc_inputs) >= 1000:\n",
    "                             if time_to_1000 == 0:\n",
    "                                    time_to_1000 = round(time.time() - time1,4)\n",
    "                        return not result\n",
    "                    # select the seed input for fairness testing\n",
    "                    time1 = time.time()\n",
    "                    inputs = seed_test_input(clusters, min(max_global, len(X)))\n",
    "                    # global flag, n_sample, n_label\n",
    "                    for num in range(len(inputs)):\n",
    "                        if time.time() - time1 >30:break\n",
    "                        index = inputs[num]\n",
    "                        sample = X[index:index+1]\n",
    "                        memory1 = sample[0] * 0\n",
    "                        memory2 = sample[0] * 0 + 1\n",
    "                        memory3 = sample[0] * 0 - 1\n",
    "                        # start global perturbation\n",
    "                        for iter in range(max_iter+1):\n",
    "                            if time.time() - time1 >20:break\n",
    "                            probs = model_prediction(sess, x, preds, sample)[0]\n",
    "                            label = np.argmax(probs)\n",
    "                            prob = probs[label]\n",
    "                            max_diff = 0\n",
    "                            n_value = -1\n",
    "                            # search the instance with maximum probability difference for global perturbation\n",
    "                            for i in range(census.input_bounds[sensitive_param-1][0], census.input_bounds[sensitive_param-1][1] + 1):\n",
    "                                if i != sample[0][sensitive_param-1]:\n",
    "                                    n_sample = sample.copy()\n",
    "                                    n_sample[0][sensitive_param-1] = i\n",
    "                                    n_probs = model_prediction(sess, x, preds, n_sample)[0]\n",
    "                                    n_label = np.argmax(n_probs)\n",
    "                                    n_prob = n_probs[n_label]\n",
    "                                    if label != n_label:\n",
    "                                        n_value = i\n",
    "                                        break\n",
    "                                    else:\n",
    "                                        prob_diff = abs(prob - n_prob)\n",
    "                                        if prob_diff > max_diff:\n",
    "                                            max_diff = prob_diff\n",
    "                                            n_value = i\n",
    "\n",
    "                            temp = copy.deepcopy(sample[0].astype('int').tolist())\n",
    "                            temp = temp[:sensitive_param - 1] + temp[sensitive_param:]\n",
    "                            # if get an individual discriminatory instance\n",
    "                            #----------------\n",
    "                            if (tuple(temp) not in tot_local_inputs) and (tuple(temp) not in tot_global_inputs):\n",
    "                                tot_global_inputs.add(tuple(temp))\n",
    "                            if len(global_disc_inputs) + len(local_disc_inputs) >= 1000:\n",
    "                                if time_to_1000 == 0:\n",
    "                                       time_to_1000 = round(time.time() - time1,4)\n",
    "                            if label != n_label and (tuple(temp) not in global_disc_inputs) and (tuple(temp) not in local_disc_inputs):\n",
    "                                if time_to_1st == 0:\n",
    "                                    time_to_1st = round(time.time() - time1,4)\n",
    "                                global_disc_inputs_list.append(temp)\n",
    "                                global_disc_inputs.add(tuple(temp))\n",
    "                                value_list.append([sample[0, sensitive_param - 1], n_value])\n",
    "                                suc_idx.append(index)\n",
    "                                # start local perturbation\n",
    "                                minimizer = {\"method\": \"L-BFGS-B\"}\n",
    "                                local_perturbation = Local_Perturbation(sess,  x, nx, x_grad, nx_grad,n_value, sensitive_param, input_shape[1], data_config[dataset])\n",
    "                                basinhopping(evaluate_local, sample, stepsize=1.0, take_step=local_perturbation,\n",
    "                                             minimizer_kwargs=minimizer,\n",
    "                                             niter=max_local)\n",
    "                                print(len(tot_inputs),num,len(local_disc_inputs),\"Percentage discriminatory inputs of local search- \" + str(\n",
    "                                          float(len(local_disc_inputs)) / float(len(tot_inputs)+1) * 100))\n",
    "                                break\n",
    "\n",
    "                            n_sample[0][sensitive_param - 1] = n_value\n",
    "                            s_grad,n_grad ,sn_grad= sess.run([tf.sign(x_grad),tf.sign(nx_grad),tf.sign(x_grad+nx_grad)], feed_dict={x: sample,nx:n_sample})\n",
    "                            # find the feature with same impact\n",
    "                            if np.zeros(data_config[dataset].params).tolist() == s_grad[0].tolist():\n",
    "                                g_diff = n_grad[0]\n",
    "                            elif np.zeros(data_config[dataset].params).tolist() == n_grad[0].tolist():\n",
    "                                g_diff = s_grad[0]\n",
    "                            else:\n",
    "                                g_diff = np.array(s_grad[0] == n_grad[0], dtype=float)\n",
    "\n",
    "                            g_diff[sensitive_param - 1] = 0\n",
    "                            if np.zeros(input_shape[1]).tolist() == g_diff.tolist():\n",
    "                                g_diff = sn_grad[0]\n",
    "                                g_diff[sensitive_param - 1] = 0\n",
    "                            if np.zeros(data_config[dataset].params).tolist() == s_grad[0].tolist() or np.array(memory1[0]).tolist()==np.array(memory3[0]).tolist():\n",
    "                                np.random.seed(seed = 2020+sd)\n",
    "                                sd += 1\n",
    "                                delta = perturbation_size\n",
    "                                s_grad[0] = np.random.randint(-delta, delta+1, (np.shape(s_grad[0])))\n",
    "\n",
    "                            g_diff = np.ones(data_config[dataset].params)\n",
    "                            g_diff[sensitive_param - 1] = 0\n",
    "                            cal_grad = s_grad * g_diff  # g_diff:\n",
    "                            memory1 = memory2\n",
    "                            memory2 = memory3\n",
    "                            memory3 = cal_grad\n",
    "                            sample[0] = clip(sample[0] + perturbation_size * cal_grad[0], data_config[dataset]).astype(\"int\")\n",
    "                            if iter == max_iter:\n",
    "                                break\n",
    "                    \n",
    "                    tot_samples = len(tot_global_inputs) + len(tot_local_inputs)\n",
    "                    tot_disc = len(global_disc_inputs) + len(local_disc_inputs)\n",
    "                    global_succ = (len(global_disc_inputs) / (len(tot_global_inputs)+1)) * 100\n",
    "                    local_succ  = (len(local_disc_inputs) /  (len(tot_local_inputs)+1)) * 100\n",
    "\n",
    "                    RQ2_table.append([len(global_disc_inputs), len(local_disc_inputs), tot_disc, local_succ, time_to_1st, time_to_1000])\n",
    "                    \n",
    "                    print(\"Total Inputs are \" + str(len(tot_inputs)))\n",
    "                    print(\"Total discriminatory inputs of global search- \" + str(len(global_disc_inputs)))\n",
    "                    print(\"Total discriminatory inputs of local search- \" + str(len(local_disc_inputs)))\n",
    "                    print('Time to first', time_to_1st)\n",
    "                    print('Time to 1000 ID', time_to_1000)\n",
    "                    # storing the fairness testing result\n",
    "#                     base_path = './output/' + dataset + '/'\n",
    "#                     if not os.path.exists(base_path):\n",
    "#                         os.makedirs(base_path)\n",
    "                    if not os.path.exists('../results/'):\n",
    "                        os.makedirs('../results/')\n",
    "                    if not os.path.exists('../results/' + dataset + '/'):\n",
    "                        os.makedirs('../results/' + dataset + '/')\n",
    "                    if not os.path.exists('../results/' + dataset + '/NeuronFair/'):\n",
    "                        os.makedirs('../results/' + dataset + '/NeuronFair/')       \n",
    "                    if not os.path.exists('../results/'+ dataset + '/NeuronFair/'+ str(sensitive_param) + '/'):\n",
    "                        os.makedirs('../results/' + dataset + '/NeuronFair/'+ str(sensitive_param) + '/')\n",
    "                        \n",
    "                    base_path ='../results/' + dataset + '/NeuronFair/'+ str(sensitive_param) + '/'\n",
    "                    np.save(base_path + 'global_samples_'+str(trial)+'.npy', np.array(global_disc_inputs_list))\n",
    "                    np.save(base_path + 'local_samples_'+str(trial)+'.npy', np.array(local_disc_inputs_list))\n",
    "                    np.save(base_path + 'suc_idx_'+str(trial)+'.npy', np.array(suc_idx))\n",
    "                    np.save(base_path + 'value_list_'+str(trial)+'.npy', np.array(value_list))\n",
    "\n",
    "            sess.close()\n",
    "            tf.reset_default_graph()       \n",
    "            np.save('../results/'+dataset+'/NeuronFair/'+ str(sensitive_param) + '/NF_RQ2_10runs.npy',RQ2_table)\n",
    "            with open('../results/'+dataset+'/NeuronFair/'+ str(sensitive_param) + '/NF_RQ2_table.csv', 'w') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(['g_disc','l_disc','tot_disc','local_succ', 'time_to_1st', 'time_to_1000'])\n",
    "                    writer.writerow(np.mean(RQ2_table,axis=0))\n",
    "                    writer.writerow(np.std(RQ2_table,axis=0))\n",
    "\n",
    "def main(argv=None):\n",
    "    dnn_fair_testing(dataset=FLAGS.dataset,\n",
    "                     sensitive_param=FLAGS.sens_param,\n",
    "                     model_path=FLAGS.model_path,\n",
    "                     cluster_num=FLAGS.cluster_num,\n",
    "                     max_global=FLAGS.max_global,\n",
    "                     max_local=FLAGS.max_local,\n",
    "                     max_iter=FLAGS.max_iter,\n",
    "                     ReLU_name=FLAGS.ReLU_name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    flags.DEFINE_string(\"dataset\", \"diabetes\", \"the name of dataset\")\n",
    "    flags.DEFINE_string(\"sens_name\", \"age\", \"the name of sens_param\")\n",
    "    flags.DEFINE_integer(\"sens_param\", 8, \"sensitive index, index start from 1, 9 for gender, 8 for race\")\n",
    "    flags.DEFINE_string(\"model_path\", \"../models/\", \"the path for testing model\")\n",
    "    flags.DEFINE_integer(\"cluster_num\", 4, \"the number of clusters to form as well as the number of centroids to generate\")\n",
    "    flags.DEFINE_integer(\"max_global\", 1000, \"maximum number of samples for global search\")\n",
    "    flags.DEFINE_integer(\"max_local\", 1000, \"maximum number of samples for local search\")\n",
    "    flags.DEFINE_integer(\"max_iter\", 40, \"maximum iteration of global perturbation\")\n",
    "    flags.DEFINE_string(\"ReLU_name\", \"ReLU5\", \"the name of bias layer of dnn model\")\n",
    "    tf.app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.20000000e+01, 8.49800000e+03, 8.52000000e+03, 4.10055974e+01,\n",
       "        1.39000000e-02, 7.11371000e+01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "np.load('../results/bank/NeuronFair/1/NF_RQ2_10runs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
